{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    " \n",
    "# Introduction to Decision Trees\n",
    " \n",
    "_Author: B Rhodes (DC)_\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lesson is all about **_decision trees_** a non-parametric method that can be used for regression or classification. We'll discuss both approaches, but spend most of our time discussing decision trees for classification. Decision trees are rule-based classifiers and have been in use for decades. The longevity of the method is due to its simplicity and effectiveness for routine classification tasks with performance that is on par with more sophisticated approaches. Decision trees and their variants are common in practice because they have decent effectiveness without sacrificing explainability.\n",
    "\n",
    "##### Learning Objectives\n",
    "Students will be able to:\n",
    "\n",
    "- What a decision tree is and what it is used for.\n",
    "- Explain how a decision tree is built.\n",
    "- Build a decision tree model in scikit-learn.\n",
    "- Tune a decision tree model and explain how tuning impacts the model.\n",
    "- Describe the key differences between regression and classification trees.\n",
    "- Determine whether or not a decision tree is an appropriate model for a given problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lesson Guide\n",
    "\n",
    "- [Introduction to Decision Trees](#introduction)\n",
    "- [Part 1: Decision Tree Classifiers](#part-one)\n",
    "    - [Entropy & Information Gain](#entropy)\n",
    "    - [Guided Exercise: Compute Information Gain](#group-exercise)\n",
    "    - [Build a Classifier in `scikit-learn`](#computer-build)\n",
    "    - [Tuning a Classification Tree](#tuning-tree)\n",
    "    - [Making Predictions for the Testing Data](#testing-preds)\n",
    "\n",
    "- [Part 2: Regression Trees](#part-two)\n",
    "    - [Comparing Regression Trees and Classification Trees](#comparing-trees)\n",
    "    - [Cut Points for Regression Trees](#cutpoint-demo)\n",
    "    - [Building a Regression Tree in `scikit-learn`](#sklearn-ctree)\n",
    "\n",
    "- [Recap](#recap)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.324959Z",
     "start_time": "2020-10-26T20:11:57.534287Z"
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn import tree \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "#from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import Image  \n",
    "#import pydotplus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Overview\n",
    "\n",
    "If you recall logistic regression generates a parametric model that can be represented by a function \n",
    "\n",
    "$$f(x) = \\frac{1}{1 + \\text{e}^{-(\\beta_0 + \\beta_1 x)}}$$\n",
    "\n",
    "Decision trees are non-parametric type of classifier that works by performing a **recursive partition of the sample space**. There is no function that describes the partition. A decision tree is a **directed acyclic graph** consiting of **nodes** connected by **edges**. The tree starts at the root node, which is the node that has no incoming edges. All other nodes have one (and only one) incoming edge. Nodes with outgoing edges are called **internal** nodes. Nodes with an incoming edge, but no outgoing edges, are called **leaves** or **terminal nodes**. \n",
    "\n",
    "<img src=\"./assets/dt_model.png\" width=\"400\">\n",
    "\n",
    "Consider the decision tree above, each internal node partitions the sample space into two (or more) sub-spaces. At each node we ask a question and the answer divides the space according to some discrete function that takes the features of the sample space as input.\n",
    "\n",
    "The simplest form is where each node considers a single feature and the space is partitioned according to the value of that feature or attribute. In general, each internal node checks for a condition and makes a decision, and every leaf node represents a discrete class. In essence, a decision tree is a just series of IF-ELSE statements (rules). Each path from the root of a decision tree to one of its leaves can be transformed into a rule simply by combining the decisions along the path to form the antecedent, and taking the leaf’s class prediction as the consequence.\n",
    "\n",
    "## Process of Building Decision Trees\n",
    "\n",
    "Decision trees are a supervised method, which means we provide it labeled data. Building decision trees follows a relatively simple process (**recursive binary splitting**) described below:\n",
    "\n",
    "1. Input a dataset of training samples consisting of features (predictors) and a target (labels). \n",
    "\n",
    "2. The decision tree is trained by making splits for the target using the values of features. Feature selection occurs by using metrics that we'll define below, such as \"__information gain__\" and \"__Gini Index__\".\n",
    "\n",
    "3. The tree is *grown* until we reach a predefined __stopping criteria__. Stopping criteria can include the max depth of the tree, minimum samples per leaf, or other similar measures.\n",
    "\n",
    "4. Make inferences on unseen data. When we present new data (unlabeled) to the tree it propagates through the nodes of the trained tree. The class predictions is determined by the resulting leaf node. \n",
    "\n",
    "### Splitting Criteria (Classification)\n",
    "\n",
    "Splits are made according to a **cost function** and the split with the lowest cost is selected. The two primary metrics used ar **entropy** and **Gini Index** (these will be described later in this notebook). These two metrics are embodied in two  different tree building algorithms.\n",
    "\n",
    "* __ID3 (Iterative Dichotomiser 3)__ uses entropy function and information gain.\n",
    "* __CART (Classification and Regression Trees)__ use Gini Index.\n",
    " \n",
    "Decision trees use a top-down *greedy search* method. At each node, the algorithm determines that best classifies the training data uses this feature to define the root of the tree. Then it considers the next best nodes, and so on. For the ID3 method above the best feature is determined by how much \"information\" or the **information gain** the feature provides. Since decision trees always try to maximize the information gain the first split (root node) have the highest information gain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifiers\n",
    "\n",
    "## Entropy & Information Gain\n",
    "\n",
    "**_Information gain_** is calculated using a statistical measure called **_Entropy_**. You may be familiar with entropy from science, mathematics, or computer science (information theory). \n",
    "\n",
    "> __Entropy is a measure of disorder or uncertainty.__\n",
    "\n",
    "Without getting into the details, we can loosely describe entropy as an indicator of how messy the data is.  A high degree of entropy always reflects \"messed-up\" data with low/no information content. The uncertainty about the content of the data, before viewing the data remains the same (or almost the same) as that before the data was available. \n",
    "\n",
    "> Claude Shannon’s entropy quantifies the amount of information in a variable, thus providing the foundation for a theory around the notion of information.\n",
    "\n",
    "For our purposes, higher entropy means less predictive power for doing data science with that data. \n",
    "\n",
    "Consider that for a given dataset the initial entropy will be high. Decision trees essentially work to reduce the entropy by separating the data and re-grouping it into their respective classes.\n",
    "\n",
    "## Decision Trees & Entropy\n",
    "Decision trees use a supervised learning approach, meaning we know the target variable for our data. We build the tree by maximizing the *purity* (decreasing the entropy) of the nodes as much as possible while making splits, aiming to have clearly defined leaf nodes. In practice, it's not generally possible to remove all the uncertainty i.e., to fully clean up the data. \n",
    "\n",
    "<img src=\"./assets/split_fs.png\" width=\"200\">\n",
    "\n",
    "As you can see the split has not fully classified the data above, the leaves are not *pure*. However, the resulting data is a lot neater than it was before the split. Using splits that focus on different features we're able to separate the data as much as possible in the leaf nodes. At each step, we want to decrease the entropy. This requires that we compute entropy before and after the split. If entropy decreases, the split is retained and we can proceed to the next step, otherwise, we try to split on different feature or stop this branch. Or we quit, in which means the resulting tree is the best solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Example: Entropy & Information Gain\n",
    "\n",
    "First, lets give a mathematical definition to entropy and information gain that you can use. Assume we have a dataset with two or more classes and $P(x_i)$ represents the probability of the class $x_i$ out of all possible classes. Then the total entropy is given by:\n",
    "\n",
    "$$H(X) = -\\sum P(x_i) . \\log_2(P(x_i))$$\n",
    "\n",
    "#### Information Gain\n",
    "When we measure information gain, we're really measuring the difference in entropy from before the split (an untidy sock drawer) to after the split (a group of white socks and underwear, and a group of non-white socks and underwear). Information gain allows us to put a number to exactly how much we've reduced our _uncertainty_ after splitting a dataset $S$ on some attribute, $F$.  The equation for information gain is:\n",
    "\n",
    "$$ IG(A, X) = H(S) - \\sum{}{P(x_i)H(x_i)}  $$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $H(S)$ is the entropy of set $S$\n",
    "* $x_i$ is a subset of the attributes contained in $F$ (all subsets $x_i$ are denoted $X$)\n",
    "* $P(x_i)$ is the proportion of the number of elements in $x_i$ to the number of elements in $X$\n",
    "* $H(x_i)$ is the entropy of a given subset $x_i$ \n",
    "\n",
    "Entropy is the metric used in the ID3 algorithm. So we use entropy to compute information gain, and then pick the attribute with the largest possible information gain to split our data on at each iteration. \n",
    "\n",
    "\n",
    "### Guided Exercise - Compute Entropy & Info Gain by hand\n",
    "\n",
    "Let's revisit the example problem from earlier. We want to decide should we go for a walk or read given the weather conditions. Here is the data in a slightly different form:\n",
    "\n",
    "|  weather | temp | humidity | windy | walk |\n",
    "|:--------:|:----:|:--------:|:-----:|:----:|\n",
    "| **overcast** | cool |   high   |   Y   |  **yes** |\n",
    "| **overcast** | mild |  normal  |   N   |  **yes** |\n",
    "| **sunny**  | cool |  normal  |   N   |  **yes** |\n",
    "| overcast |  hot |   high   |   Y   |  no  |\n",
    "|   **sunny**  |  hot |  normal  |   Y   |  **yes** |\n",
    "|   rain   | mild |   high   |   N   |  no  |\n",
    "|   rain   | cool |  normal  |   N   |  no  |\n",
    "|   **sunny**  | mild |   high   |   N   |  **yes** |\n",
    "|   **sunny**  | cool |  normal  |   Y   |  **yes** |\n",
    "|   **sunny**  | mild |  normal  |   Y   |  **yes** |\n",
    "| **overcast** | cool |   high   |   N   |  **yes** |\n",
    "|   rain   | cool |   high   |   Y   |  no  |\n",
    "|   sunny  |  hot |  normal  |   Y   |  no  |\n",
    "|   **sunny**  | mild |   high   |   N   |  **yes** |\n",
    "\n",
    "**Exercise**: write a function `entropy()` to calculate total entropy for a given discrete probability distribution `Pi`.\n",
    "\n",
    "- The function should input a probability distribution `Pi` as an array of class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.339240Z",
     "start_time": "2020-10-26T20:12:00.328256Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-05b0fb7ccf3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# test the function with an assert statement.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Then verify the function with the examples below. Expected results are listed at the bottom of this cell.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "def entropy(Pi):\n",
    "    \"\"\"\n",
    "    return the Entropy of a probability distribution:\n",
    "    entropy(p) = - SUM (Pi * log(Pi) )\n",
    "    \"\"\"\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    pass # replace this with your function\n",
    "\n",
    "# test the function with an assert statement.\n",
    "assert entropy([1, 1]) == 1\n",
    "\n",
    "# Then verify the function with the examples below. Expected results are listed at the bottom of this cell.\n",
    "print(entropy([1, 1])) # Maximum Entropy e.g. a coin toss\n",
    "print(entropy([2, 10])) # A random mix of classes\n",
    "print(entropy([0, 7])) # No entropy, ignore the - with zero , its there due to log function\n",
    "print(entropy([11,6])) # Another random mix of classes\n",
    "\n",
    "\n",
    "# Expected outcomes\n",
    "#1.0\n",
    "#0.6500224216483541\n",
    "#-0.0\n",
    "#0.9366673818775626"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Write a function `IG(D,a)` to calculate the information gain \n",
    "\n",
    "- The function should input `D` as a class distribution array for target class, and `a` the class distribution of the attribute to be tested\n",
    "- Using the `entropy()` function above, calculate the information gain as:\n",
    "\n",
    "$$IG(D,A) = Entropy(D) - \\sum(\\frac{|D_i|}{|D|}.Entropy(D_i))$$\n",
    "\n",
    "where `Di` represents distribution of each class in `a`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.357917Z",
     "start_time": "2020-10-26T20:12:00.343663Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d1f20860435d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mIG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.1415414066556504\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m# set of example of the dataset - distribution of classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtest_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Yes, No\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def IG(D, a):\n",
    "    '''\n",
    "    return the information gain:\n",
    "    gain(D, a) = entropy(D)− SUM( |Di| / |D| * entropy(Di) )\n",
    "    '''\n",
    "    \n",
    "    #your code here\n",
    "\n",
    "    pass # replace this with your function\n",
    "\n",
    "\n",
    "     \n",
    "    \n",
    "assert IG([8, 8], [ [3,1], [2,6], [2,2] ]) == 0.1415414066556504\n",
    "# set of example of the dataset - distribution of classes\n",
    "test_dist = [8, 8] # Yes, No\n",
    "# attribute, number of members (feature)\n",
    "test_attr = [ [4,0], [1,7], [0,4] ] # class1, class2, class3 of attr1 according to YES/NO classes in test_dist\n",
    "\n",
    "print(IG(test_dist, test_attr))\n",
    "\n",
    "# Expected value\n",
    "# 0.7282177784002017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the Root Node\n",
    "Use the above functions to determine the root node. \n",
    "1. Determine the class distribution for each target class (a list of frequencies).\n",
    "2. Determine the class distribution for each target class for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.379825Z",
     "start_time": "2020-10-26T20:12:00.362059Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5143f8c1bdb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Your code here - fill in the distributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwill_walk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Y, N\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# feature categories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwindy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;31m# Y,N: Y, N\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "# Your code here - fill in the distributions\n",
    "will_walk = [Y,N] # Y, N\n",
    "\n",
    "# feature categories\n",
    "windy = [ [Y,N], [Y,N] ] # Y,N: Y, N\n",
    "humidity = [ [4,3], [5,2] ] # high, normal: Y,N\n",
    "temp = [ [1,2], [4,1], [4,2] ] # hot, mild, cool: Y,N\n",
    "weather = [ [6,1], [3,1], [0,3] ]  # sunny, overcast, rain: Y,N\n",
    "\n",
    "\n",
    "# define dictionary for each feature\n",
    "conditions = {'windy':windy, 'humidity':humidity, 'temp':temp, 'weather':weather}\n",
    "# loop thru the conditions\n",
    "print(\"Information Gain by Condition:\")\n",
    "\n",
    "# loop thru the conditions & build dictionary to hold Information Gain for each feature\n",
    "gain = {}\n",
    "for condition, dist in conditions.items():\n",
    "    result = IG(will_walk, dist)\n",
    "    gain[condition] = result\n",
    "    print(condition+':', gain[condition])\n",
    "    max_gain_condition = max(gain, key=gain.get)\n",
    "\n",
    "print(\"\\nSplit on max gain condition: \", max_gain_condition)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the Next  Node (sunny)\n",
    "Repeat the process relative to the sunny node. \n",
    "1. Determine the class distribution for each target class (a list of frequencies).\n",
    "2. Determine the class distribution for each target class for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.458250Z",
     "start_time": "2020-10-26T20:12:00.383338Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weather' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0d2220489afe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msunny_walk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweather\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# we only need the first distribution from outlook.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# condition:outcome\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwindy_sun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;31m# y,n:y,n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtemp_sun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# hot, mild, cool:y,n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weather' is not defined"
     ]
    }
   ],
   "source": [
    "sunny_walk = weather[0] # we only need the first distribution from outlook.\n",
    "\n",
    "# condition:outcome\n",
    "windy_sun = [ [3,1], [3,0] ] # y,n:y,n\n",
    "temp_sun = [ [1,1],[3,0], [2,0]] # hot, mild, cool:y,n\n",
    "humidity_sun = [[2,0],[4,1]] # hi,norm:y,n\n",
    "\n",
    "\n",
    "# define dictionary for each remaining feature\n",
    "conditions_sunny = {'windy':windy, 'humidity':humidity, 'temp':temp}\n",
    "\n",
    "print(\"Information Gain by Condition:\")\n",
    "\n",
    "# loop thru the conditions & build dictionary to hold Information Gain for each feature\n",
    "gain_sunny = {}\n",
    "for condition, dist in conditions_sunny.items():\n",
    "    result = IG(will_walk, dist)\n",
    "    gain_sunny[condition] = result\n",
    "    print(condition+':', gain_sunny[condition])\n",
    "    max_gain_sunny = max(gain_sunny, key=gain_sunny.get)\n",
    "\n",
    "print(\"\\nSplit on max gain for sunny condition: \", max_gain_sunny)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees with scikit-learn\n",
    "\n",
    "We've had an overview of decision trees and how they are built using entropy. Here we show how to use decision trees (for classification) using scikit-learn and pandas. We'll walk through an example showing the basics and understanding the resulting decision tree. As before we'll use scikit-learn's consistent interface for running classifiers/regressors. Since this is a classification task we use the same metrics as we've used before (*e.g.* confusion matrix, roc, auc, etc.). \n",
    "\n",
    "Let's analyze the dataset above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Exercise\n",
    "\n",
    "The \"walk\" dataset is available in the repo as `walk.csv`. \n",
    "1. Import the necessary modules.\n",
    "2. Load the dataset into a dataframe\n",
    "3. Encode the data as numerical values (all our features are categorical).\n",
    "    1. Our target variable is binary so we'll use ```LabelEncoder.```\n",
    "    2. The features are multi-class so we'll use ```OneHotEncoder.```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instructions:** \n",
    "- Apply labels to target variable such that `yes=1` and `no=0`\n",
    "- Apply one hot encoding to the feature set, creating ten features (outlook x 3, temp x 3, humidity x 2 , wind x 2) \n",
    "- Print the resulting features and check shape\n",
    "\n",
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.477189Z",
     "start_time": "2020-10-26T20:12:00.462437Z"
    }
   },
   "outputs": [],
   "source": [
    "# # For reference so we don't have to scroll\n",
    "\n",
    "# # sklearn imports\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.tree import DecisionTreeClassifier \n",
    "# from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, classification_report\n",
    "# from sklearn import tree \n",
    "# from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# #from sklearn.externals.six import StringIO  \n",
    "# from sklearn.tree import export_graphviz\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# from IPython.display import Image  \n",
    "# #import pydotplus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.516952Z",
     "start_time": "2020-10-26T20:12:00.479586Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "walk_df = pd.read_csv('./data/walk.csv')\n",
    "walk_data = pd.read_csv('./data/walk.csv')\n",
    "walk_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Data\n",
    "As mentioned all our features are categorical so we need to encode them to numerical values. Previously we used ```pandas'``` ```get_dummies()``` method to create dummy variables. This is also known as one-hot encoding. Below we use ```sci-kit learn's``` built-in methods to encode our data. We'll use ```LabelEncoder``` to encode binary features or targets and we use the ```OneHotEncoder``` to encode non-binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.580603Z",
     "start_time": "2020-10-26T20:12:00.558339Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create label encoder instance\n",
    "lb = LabelEncoder() \n",
    "\n",
    "# Create Numerical labels for classes\n",
    "walk_df['walk_'] = lb.fit_transform(walk_df['walk'] ) \n",
    "walk_df['weather_'] = lb.fit_transform(walk_df['weather']) \n",
    "walk_df['temp_'] = lb.fit_transform(walk_df['temp'] ) \n",
    "walk_df['humidity_'] = lb.fit_transform(walk_df['humidity'] ) \n",
    "walk_df['windy_'] = lb.fit_transform(walk_df['windy'] ) \n",
    "\n",
    "# Split features and target variable\n",
    "X_enc = walk_df[['weather_', 'temp_', 'humidity_', 'windy_']] \n",
    "y = walk_df['walk_']\n",
    "\n",
    "# Instantiate a one hot encoder\n",
    "one_enc = OneHotEncoder(categories='auto')\n",
    "\n",
    "# Fit the feature set X\n",
    "one_enc.fit(X_enc)\n",
    "\n",
    "# Transform X to onehot array \n",
    "onehotX = one_enc.transform(X_enc).toarray()\n",
    "\n",
    "print(\"OneHot Encoded Array\")\n",
    "print(onehotX)\n",
    "print()\n",
    "print(\"Shape of OneHotEncoded Array\")\n",
    "print(onehotX.shape)\n",
    "print()\n",
    "print(\"Shape of Original Feature Array\")\n",
    "print(X_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.615532Z",
     "start_time": "2020-10-26T20:12:00.598615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Demo purposes only - let's look at the one-hot encoded matrix\n",
    "cols = ['weather_0', 'weather_1','weather_2','temp_0','temp_1','temp_2', 'humidity_0','humidity_1', 'windy_0','windy_1']\n",
    "\n",
    "onehotX_df = pd.DataFrame(onehotX, columns=cols)\n",
    "onehotX_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.626313Z",
     "start_time": "2020-10-26T20:12:00.621282Z"
    }
   },
   "outputs": [],
   "source": [
    "# reset X for demo purposes\n",
    "X = walk_data[['weather', 'temp', 'humidity', 'windy']] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the equivalence between one-hot encoding in sklearn and `get_dummies()` in pandas let's look at how we would do this in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.652073Z",
     "start_time": "2020-10-26T20:12:00.629863Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = X.astype('category')  # data is numerical, so we need to recast it as categorical\n",
    "X_dummy = pd.get_dummies(X, drop_first=True) # get_dummies and drop the first\n",
    "X_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.662301Z",
     "start_time": "2020-10-26T20:12:00.654099Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at class imbalance\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.964122Z",
     "start_time": "2020-10-26T20:12:00.664167Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalized to see ratios\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Train-Test Split\n",
    "\n",
    "We've encoded our data now we need to split our data into training and test data. Pass the encoded features and target to ```train_test_split``` using a 60/40 split. \n",
    "\n",
    "**Question:** Is train test split the best approach here? Why? What other approach might work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.973883Z",
     "start_time": "2020-10-26T20:12:00.966641Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the one-hot encoded data\n",
    "X_train, X_test , y_train,y_test = train_test_split(onehotX, y, test_size = 0.4, random_state = 42) \n",
    "\n",
    "## Split the pandas dummy data\n",
    "#X_train, X_test , y_train,y_test = train_test_split(X_dummy, y, test_size = 0.4, random_state = 42) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Decision Tree \n",
    "\n",
    "No need to guess here, we use the same scikit-learn pattern to build the model. We use the same 3-step process, which includes `.fit()` and `.predict()`. We first create an instance of the classifier with appropriate parameter values, then we fit the data to the model using `.fit()` and make predictions with the test data (`X_test`) using `.predict()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.983224Z",
     "start_time": "2020-10-26T20:12:00.977136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "clf= DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train,y_train) \n",
    "\n",
    "# Generate inferences\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model Performance\n",
    "\n",
    "Our model is trained and we've made some inferences so we need to determine how well our model performs. This is a classification problem so we use the standard confusion matrix and related metrics. Notice that this step is the same as when we used KNN or logistic regression. It doesn't matter which classifier you are using, the performance measures are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:00.996174Z",
     "start_time": "2020-10-26T20:12:00.987801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Look at feature importance\n",
    "print(len(df.feature_importances_))\n",
    "\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above array would be hard to sort out if we had many more features. Below is a simple construct to view the importance and associated feature name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.029910Z",
     "start_time": "2020-10-26T20:12:01.006638Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## put feature importance into a dataframe - uncomment only one statement below.\n",
    "\n",
    "# use this if you used the one-hot encoded data\n",
    "pd.DataFrame({'feature':onehotX_df.columns, 'importance':clf.feature_importances_})\n",
    "\n",
    "# use this if you used the pandas dummy data\n",
    "#pd.DataFrame({'feature':X_train.columns, 'importance':clf.feature_importances_})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Evaluate the Results\n",
    "We can compute metrics now that we have a model. But how do we know if our model is worth it? First we compare it to a baseline model, which in this case means, determinging what the most frequent class is?\n",
    "\n",
    "So we define our baseline model on the most frequent class in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.061679Z",
     "start_time": "2020-10-26T20:12:01.032644Z"
    }
   },
   "outputs": [],
   "source": [
    "# look at the class balance again.\n",
    "y.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.077103Z",
     "start_time": "2020-10-26T20:12:01.065135Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline model is defined by the most frequent class in our training data\n",
    "\n",
    "y_baseline = y_train.value_counts().index[0]\n",
    "baseline_acc = round(y_train.value_counts(normalize=True)[y_baseline]*100,2)\n",
    "print(f'Most Frequent Category: {y_baseline}')\n",
    "print(f'Percentage Most Frequent Category: {baseline_acc}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.093254Z",
     "start_time": "2020-10-26T20:12:01.079933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracy , AUC and Confusion matrix \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# get roc auc info\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(\"Accuracy is : \"+ str(round(accuracy,3)*100)+\"%\")\n",
    "print(\"AUC is : \"+str(round(roc_auc,3)))\n",
    "\n",
    "# confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.507607Z",
     "start_time": "2020-10-26T20:12:01.098124Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the ROC \n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve for Test Set')\n",
    "plt.legend(loc='lower right')\n",
    "print('Test AUC: {}'.format(auc(fpr, tpr)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.538273Z",
     "start_time": "2020-10-26T20:12:01.516701Z"
    }
   },
   "outputs": [],
   "source": [
    "## Compute other confusion matrix metrics\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "#precision tp/(tp+fp)\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "\n",
    "# Sensitivity (recall) tp/(tp+fn)\n",
    "sensitivity = tp/(tp+fn)\n",
    "\n",
    "# Specificity tn/(tn+fp)\n",
    "specificity = tn/(tn+fp)\n",
    "\n",
    "# false negative rate (miss rate) fn/(fn+tp)\n",
    "fnr = fn/(fn+tp)\n",
    "\n",
    "fpr = fp/(fp+tn)\n",
    "\n",
    "\n",
    "print(f'precision: {precision}')\n",
    "print(f'sensitivity: {sensitivity}')\n",
    "print(f'specificity: {specificity}')\n",
    "\n",
    "# f1 score - (2*tp)/(2*tp+fp+fn))\n",
    "f1 = (2*tp)/(2*tp+fp+fn)\n",
    "print(f'f1: {f1}')\n",
    "\n",
    "\n",
    "print(f'fnr: {fnr}')\n",
    "print(f'fpr: {fpr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.554395Z",
     "start_time": "2020-10-26T20:12:01.542897Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_report =   classification_report(y_test, y_pred)\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-paced Exercise - Forgery or not Forgery\n",
    "For this in-class exercise, we'll work with the \"UCI Bank Note Authentication Dataset'. This data identifies genuine and forged banknotes and is based on images of actual currency (forged and real). The notes were first digitized, followed by a numerical transformation using wavelet transform techniques. The resulting set of engineered features are all continuous so no categorical data to worry about.\n",
    "\n",
    "We have following features and target in the dataset. \n",
    "\n",
    "1. __Variance__ of Wavelet Transformed image (continuous) \n",
    "2. __Skewness__ of Wavelet Transformed image (continuous) \n",
    "3. __Curtosis__ of Wavelet Transformed image (continuous) \n",
    "4. __Entropy__ of image (continuous) \n",
    "5. __Class__ (integer) - Target/Label \n",
    "\n",
    "We've already imported all the libraries we need so just start with loading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "\n",
    "Load the dataset in a DataFrame, perform some basic EDA, and generally get a feel for the data we'll be working with.\n",
    "\n",
    "- The dataset is at ```url = \"data/banknote.csv\"``` Load this as a pandas dataframe. Note that there is no header information in this dataset, so be sure to use `header=None`.\n",
    "- Assign column names 'Variance', 'Skewness', 'Curtosis', 'Entropy', 'Class' to dataset in the given order.\n",
    "- View the shape and data types of dataset, as well as summary statistics.\n",
    "- Check for frequency of positive and negative examples in the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:19:14.408132Z",
     "start_time": "2020-10-26T20:19:14.404623Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-8530f91f72c8>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-8530f91f72c8>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    banknotes_df = None.  # replace to read in the data\u001b[0m\n\u001b[1;37m                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Your code here\n",
    "\n",
    "path = \"../data/banknote.csv\"\n",
    "\n",
    "banknotes_df = None.  # replace to read in the data\n",
    "\n",
    "# Assign column names\n",
    "\n",
    "# verify the data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.600279Z",
     "start_time": "2020-10-26T20:12:01.586650Z"
    }
   },
   "outputs": [],
   "source": [
    "# check the shape and data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.659449Z",
     "start_time": "2020-10-26T20:12:01.604316Z"
    }
   },
   "outputs": [],
   "source": [
    "# check the summary statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.673680Z",
     "start_time": "2020-10-26T20:12:01.662543Z"
    }
   },
   "outputs": [],
   "source": [
    "# check for any imbalance in class labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** There are no major imbalances in the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Assign Feature and Target Variables \n",
    "\n",
    "Next we create our feature set `X` and labels `y`. \n",
    "- Create `X` and `y` by selecting the appropriate columns from the dataset\n",
    "- Create a 80/20 split on the dataset for training/testing. Use `random_state=42` for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.682936Z",
     "start_time": "2020-10-26T20:12:01.676404Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code here\n",
    "feature_cols = None\n",
    "\n",
    "X = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:28:47.081810Z",
     "start_time": "2020-10-26T20:28:46.979659Z"
    }
   },
   "outputs": [],
   "source": [
    "# train test split \n",
    "# Create a 80/20 split on the dataset for training/testing. \n",
    "# Use `random_state=42` for reproducibility\n",
    "\n",
    "X_train, X_test , y_train, y_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Classifier and Make Predictions\n",
    "Use the standard process to build a classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.711738Z",
     "start_time": "2020-10-26T20:12:01.698260Z"
    }
   },
   "outputs": [],
   "source": [
    "# build your model and make predictions\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.727187Z",
     "start_time": "2020-10-26T20:12:01.714094Z"
    }
   },
   "outputs": [],
   "source": [
    "# create dataframe of feature importance\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Model Performance\n",
    "\n",
    "We can now use different evaluation measures to check the predictive performance of the classifier. \n",
    "- State what the baseline model is and the baseline accuracy for this data.\n",
    "- Check the accuracy of your classifier, AUC and create a confusion matrix \n",
    "- Plot the ROC\n",
    "- Interpret the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.741738Z",
     "start_time": "2020-10-26T20:12:01.729371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "\n",
    "# Baseline model is defined by the most frequent class\n",
    "\n",
    "# your code here print the model and the relevant metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:01.757309Z",
     "start_time": "2020-10-26T20:12:01.745748Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracy , AUC and Confusion matrix \n",
    "accuracy = None\n",
    "\n",
    "# get roc auc info\n",
    "fpr, tpr, thresholds = None\n",
    "roc_auc = None\n",
    "\n",
    "print(\"Accuracy is : \"+ str(round(accuracy,3)*100)+\"%\")\n",
    "print(\"AUC is : \"+str(round(roc_auc,3)))\n",
    "\n",
    "cm = None\n",
    "# confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:02.112679Z",
     "start_time": "2020-10-26T20:12:01.759974Z"
    }
   },
   "outputs": [],
   "source": [
    "# Do not change this code.\n",
    "\n",
    "# Plot the ROC \n",
    "plt.figure(figsize=(10, 8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve for Test Set')\n",
    "plt.legend(loc='lower right')\n",
    "print('Test AUC: {}'.format(auc(fpr, tpr)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:02.136719Z",
     "start_time": "2020-10-26T20:12:02.116779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Accuracy , AUC and Confusion matrix \n",
    "accuracy = None\n",
    "\n",
    "# get roc auc info\n",
    "fpr, tpr, thresholds = None\n",
    "roc_auc = None\n",
    "\n",
    "print(\"Accuracy is : \"+ str(round(accuracy,3)*100)+\"%\")\n",
    "print(\"AUC is : \"+str(round(roc_auc,3)))\n",
    "\n",
    "cm = None\n",
    "# confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "print()\n",
    "## Compute other confusion matrix metrics\n",
    "\n",
    "tn, fp, fn, tp = None\n",
    "\n",
    "#precision tp/(tp+fp)\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "\n",
    "# Sensitivity (recall) tp/(tp+fn)\n",
    "sensitivity = tp/(tp+fn)\n",
    "\n",
    "# Specificity tn/(tn+fp)\n",
    "specificity = tn/(tn+fp)\n",
    "\n",
    "# false negative rate (miss rate) fn/(fn+tp)\n",
    "fnr = fn/(fn+tp)\n",
    "\n",
    "fpr = fp/(fp+tn)\n",
    "\n",
    "\n",
    "print(f'precision: {precision}')\n",
    "print(f'sensitivity: {sensitivity}')\n",
    "print(f'specificity: {specificity}')\n",
    "\n",
    "# f1 score - (2*tp)/(2*tp+fp+fn))\n",
    "f1 = (2*tp)/(2*tp+fp+fn)\n",
    "print(f'f1: {f1}')\n",
    "\n",
    "\n",
    "print(f'fnr: {fnr}')\n",
    "print(f'fpr: {fpr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-26T20:12:02.161130Z",
     "start_time": "2020-10-26T20:12:02.138720Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_report = None\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
